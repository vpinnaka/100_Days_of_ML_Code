# 100_Days_of_ML_Code
This is the repository to showcase my work for accomplishing 100DaysofMLCode

### Day 1: July 5, 2018 

**Today's Progress**: I've created repository for exploring titanic data set.

**Thoughts** Earlier I was using MOOCS for learning ML, while doing assignments they have provided the sample codes which never gave me a chance to code completly from scratch. But now I came to know that I have to work on basic pandas syntax and need lot of understanding to code from scratch

**Link(s) to work**
[Titanic dataset exploration](https://github.com/vpinnaka/100_Days_of_ML_Code/blob/master/Day1/Titanic%20Dataset%20Exploration.ipynb)

### Day2: July 7, 2018 

**Today's Progress**: I've analyzed the dataset for categorical, continious features.

**Thoughts** Analaysing each attributes is time taking if we have more number of features

**Link(s) to work**
[Titanic dataset exploration](https://github.com/vpinnaka/100_Days_of_ML_Code/blob/master/Day2/Titanic%20Dataset%20Exploration.ipynb)

### Day3: July 8, 2018 

**Today's Progress**: Completed K-Means clustering videos in Udacity ML Nanodegree .

**Thoughts** K-Means clustering have limitations, the major one local minima. When the centeroids are inteitalies to local minima while picking randomly will cause failure of K-Means clustering. One way is to run K-Means algorithem multiple times and get the ensemble of all the phases. If more number of clusters are assigned the more local minimas exists.

**Link(s) to work**
[K-Means Visulization](http://www.naftaliharris.com/blog/visualizing-k-means-clustering/)
[sklean K-Means](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)


### Day4: July 9, 2018 

**Today's Progress**: Started working on K-Means clustering mini project in Udacity ML Nanodegree .

**Thoughts** K-Means clustering have limitations, the major one local minima. When the centeroids are inteitalies to local minima while picking randomly will cause failure of K-Means clustering. One way is to run K-Means algorithem multiple times and get the ensemble of all the phases. If more number of clusters are assigned the more local minimas exists.

**Link(s) to work**
[k-means Clustering of Movie Ratings](https://view5c8205b9.udacity-student-workspaces.com/notebooks/k-means%20Clustering%20of%20Movie%20Ratings.ipynb)

### Day5: July 10, 2018 

**Today's Progress**: completed K-Means clustering mini project in Udacity ML Nanodegree .

**Thoughts** Recommendation engine that is coded in this project can be extended to other datasets such as item recommendation for Amazon or restauerent recommendation engine etc. In this mini-project Ihave graspd the overview of recommendation engines but coding a recommendation engine from scratch will defnitly help me to learn better and utilizing other algorithems for clustering will be a better approach. 

**Some Improvement**
* Colloborative filtering is performed here, but need to investigate other approaches
* Convert this to a flask api so that I can develop a freontend on top this

**Link(s) to work**
* [siraj raval AWS DSSTNE](https://www.youtube.com/watch?v=eKmIVU8EUbw) this video includes a paper about recommendation engines read this
* [siraj raval recommendation system](https://www.youtube.com/watch?v=9gBC9R-msAk)

### Day6: July 12, 2018 

**Today's Progress**: Worked on Titanic dataset project and analysed the impoertant features that contribute to the Survival.

**Thoughts** Makeing data assumptions and verifying them by anylizing the data is the first step to understand data. Any data science project requires this phase. 

**Link(s) to work**
[Titanic dataset exploration](https://github.com/vpinnaka/100_Days_of_ML_Code/blob/master/Day6/Titanic%20Dataset%20Exploration.ipynb) 

### Day7: July 14, 2018 

**Today's Progress**: Completed Hirachical clustering techniques and DBSCAN.

**Thoughts** Hierarchical clustering techniques are useful to get more info about dataset by the dendogram it creates. Dendogram will visulize the capability to cluster the points. DBSCAN on the other hand is efficient for data with noise and can beat any other algorithem in this case

**Link(s) to work**
[Hierachical clustering](https://github.com/vpinnaka/100_Days_of_ML_Code/blob/master/Day7/Hierarchical_clustering/Hierarchical%20Clustering%20Lab.ipynb) 
[DBSCAN](https://github.com/vpinnaka/100_Days_of_ML_Code/blob/master/Day7/DBSCAN/DBSCAN%20Notebook.ipynb)

### Day8: July 15, 2018 

**Today's Progress**: Completed Gaussian mixture model.

**Thoughts** GMM is a propabilistic algorithm where every point will have propabilities of each cluster. Expectation maximization algorithm is ued to find GMM. Also studied cluster validation techniques such as Adjusted Rand Index, Shilouette Cofficients

**Link(s) to work**
[Gaussian mixture model](https://github.com/vpinnaka/100_Days_of_ML_Code/blob/master/Day8/GMM_Clustering/GMM%20Clustering%20and%20Cluster%20Validation%20Lab.ipynb) 
